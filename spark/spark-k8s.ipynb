{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "hdfs_fs = 'hdfs://hadoop-master.hadoop-domain.default-tenant.svc.cluster.local:9000'\n",
    "v3io_fs =  os.getenv('V3IO_HOME_URL')\n",
    "\n",
    "print(f\"HDFS: {hdfs_fs}\")\n",
    "print(f\"V3IO: {v3io_fs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "krb5_conf_dir = '/User/conf/kerberos'\n",
    "hadoop_conf_dir = '/User/conf/hadoop'\n",
    "krb5_cc_name = 'FILE:' + os.path.join(krb5_conf_dir,'krb5_ccache')\n",
    "krb5_config_file = os.path.join(krb5_conf_dir,'krb5.conf')\n",
    "krb5_keytab_file = os.path.join(krb5_conf_dir,'krb5.keytab')\n",
    "\n",
    "print(f\"KRB5CCNAME: {krb5_cc_name}\")\n",
    "print(f\"HADOOP_CONF_DIR: {hadoop_conf_dir}\")\n",
    "print(f\"KRB5_CONFIG: {krb5_config_file}\")\n",
    "print(f\"JVM config: {jvm_config_option}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These should be pre-configured in the Jupyter service configuration. Use this only if they're not.\n",
    "# os.environ['KRB5CCNAME'] = krb5_cc_name\n",
    "# os.environ['HADOOP_CONF_DIR'] = hadoop_conf_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kinit -k -t /User/conf/kerberos/krb5.keytab hdfs/hadoop-master.hadoop-domain.default-tenant.svc.cluster.local@EXAMPLE.COM\n",
    "!klist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Example\") \\\n",
    "    .master('k8s://https://kubernetes.default.svc:443') \\\n",
    "    .config('spark.kerberos.principal','hdfs/hadoop-master.hadoop-domain.default-tenant.svc.cluster.local@EXAMPLE.COM') \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3io_path = os.path.join(v3io_fs,'examples','demo.csv')\n",
    "print(v3io_path)\n",
    "\n",
    "v3io_df = spark.read.csv(v3io_path)\n",
    "v3io_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(hdfs_fs,'user/hdfs/output.csv')\n",
    "print(output_path)\n",
    "\n",
    "v3io_df.write.csv(output_path, mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs_df = spark.read.csv(output_path)\n",
    "hdfs_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
